# Config File:

######################################################
# INPUTS
######################################################
input_video_path: "/root/autodl-tmp/res.mp4" # Path to the input video file
output_video_dir: "output"  # Directory to save the outputs

save_frames: 1 # 0: No, 1: Yes

# Width and Height of the Input and Output videos
# If zero the input's video dimension will be used otherwise the input will be resized
# 视频文件记得做一下预处理

width: 512
height: 512

prompt: "A man with perfect++ face++ , (perfect face)++, (perfect eyes)++ fully dressed, (sharp features)+, (intense eyes)+,  sumptuous artwork, breath of the wild, masterpiece, best quality, sharp focus, dramatic lighting, 8k, uhd, dslr, vivid color, matte painting ,  high quality"
n_prompt: "easynegative+, nudity, tint, blue tint, blue, mask++, (bad face)+++, (worst quality)+, (low quality)+, lowres, bad anatomy, (monochrome)++, (grayscale)+, (text, font, logo, copyright, watermark)++, wrong face, wrong hands, wrong legs, wrong feet, (nsfw,nude)+"

# Additional Basic Parameters
start_time: "00:00:00" # Time in HH:MM:SS format to start reading the input video
end_time: "00:00:03" # Time in HH:MM:SS format to stop reading the input video

# Use the last frame of each AnimateDiff output sequence as reference for the next epoch using the following img2img strength
overlap_strength: 0.92


use_lcm: 0 # 0: No, 1: Yes - If used most of the settings related to LoRA, DreamBooth, ControlNet, will be ignored as LCM models do not support them.
# It is also worth noting that LCM does not have support for negative prompt at the moment.


######################################################
# MODELS
######################################################

# Base model that AnimateDiff uses to create the initial architecture from (it needs to be in HuggingFace format (.bin))
pretrained_model_path: "models/StableDiffusion/Yntec/mistoonAnime2"

# Optional Alternative AutoEncoder (VAE)
vae_path: "models/VAE/vae-ft-mse-840000-ema-pruned.ckpt" #"models/VAE/vae-ft-ema-560000-ema-pruned.safetensors"

# Optional DreamBooth Model (full)
# dreambooth_path: "models/DreamBooth_LoRA/dreamshaper_8.safetensors" 

# Optional LoRA model to be used
lora_model_path: "" #models/DreamBooth_LoRA/genshin_impact_yoimiya.safetensors
lora_weight: #0.8

# Motion Module to be used - versions of the config and the model must match
inference_config_path: "configs/inference/inference-v2.yaml"
motion_module: "models/Motion_Module/mm_sd_v15_v2.ckpt"

# Optional ControlNet Models to be used - will be downloaded automatically
controlnets:
  - lllyasviel/control_v11p_sd15_openpose
  # - lllyasviel/control_v11p_sd15_lineart
  # - lllyasviel/control_v11p_sd15_mlsd
  # - lllyasviel/sd-controlnet-canny
  - lllyasviel/control_v11p_sd15_softedge
  # - lllyasviel/sd-controlnet-mlsd
  # - lllyasviel/sd-controlnet-openpose
  # - lllyasviel/control_v11p_sd15s2_lineart_anime
  # - lllyasviel/sd-controlnet-hed

cond_scale: 
  - 1.0
  - 0.5
  # - 1.0
  # - 0.4


######################################################
# PARAMETERS
######################################################

upscale: 2 # Upscaler value for the input image
use_face_enhancer: 0 # 0: No, 1: Yes
upscale_first: 1 # Upscale before applying face enhancement - better results but slower: 0: No, 1: Yes

frame_count: 16 # How many co-related frames are produced by AnimateDiff - defaults to 16
overlap_length: 8 # Number of frames from previous output frames to be present in the current frames (helps with consistency)

seed: 16086 
steps: 30
guidance_scale: 7.5
strength: 1.0 # Strengtht of the noise to be added to input latents - if 1.0 the img2img effect is nil


# Choice of scheduler: "DDIMScheduler", "EulerDiscreteScheduler" ,"DPMSolverMultistepScheduler","EulerAncestralDiscreteScheduler","LMSDiscreteScheduler","PNDMScheduler"
scheduler:  "EulerDiscreteScheduler"


fps: 32 # The framerate to sample the input video
fps_ffmpeg: 32 # The framerate of the output video
crf: 23 # A measure of quality - lower is better 


######################################################
# ADDITIONAL
######################################################

ffmpeg_path: "/root/miniconda3/envs/cuda11_8_env/bin/ffmpeg"